{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    " # A Beginner's attempt at Titanic Survival prediction competition #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input the Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Passenger Info</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Passenger Info  PassengerId  Survived  Pclass  \\\n",
       "0                         1         0       3   \n",
       "1                         2         1       1   \n",
       "2                         3         1       3   \n",
       "3                         4         1       1   \n",
       "4                         5         0       3   \n",
       "..                      ...       ...     ...   \n",
       "886                     887         0       2   \n",
       "887                     888         1       1   \n",
       "888                     889         0       3   \n",
       "889                     890         1       1   \n",
       "890                     891         0       3   \n",
       "\n",
       "Passenger Info                                               Name     Sex  \\\n",
       "0                                         Braund, Mr. Owen Harris    male   \n",
       "1               Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
       "2                                          Heikkinen, Miss. Laina  female   \n",
       "3                    Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
       "4                                        Allen, Mr. William Henry    male   \n",
       "..                                                            ...     ...   \n",
       "886                                         Montvila, Rev. Juozas    male   \n",
       "887                                  Graham, Miss. Margaret Edith  female   \n",
       "888                      Johnston, Miss. Catherine Helen \"Carrie\"  female   \n",
       "889                                         Behr, Mr. Karl Howell    male   \n",
       "890                                           Dooley, Mr. Patrick    male   \n",
       "\n",
       "Passenger Info   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0               22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1               38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2               26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3               35.0      1      0            113803  53.1000  C123        S  \n",
       "4               35.0      0      0            373450   8.0500   NaN        S  \n",
       "..               ...    ...    ...               ...      ...   ...      ...  \n",
       "886             27.0      0      0            211536  13.0000   NaN        S  \n",
       "887             19.0      0      0            112053  30.0000   B42        S  \n",
       "888              NaN      1      2        W./C. 6607  23.4500   NaN        S  \n",
       "889             26.0      0      0            111369  30.0000  C148        C  \n",
       "890             32.0      0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tit = pd.read_csv('C://Users//91836//Documents//DataSets//Titanic//train.csv')\n",
    "tit_test = pd.read_csv('C://Users//91836//Documents//DataSets//Titanic//test.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "tit.rename_axis(\"Passenger Info\",axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA values per column:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64 (891, 12)\n",
      "Object columns:\n",
      "                                                 Name     Sex  \\\n",
      "0                            Braund, Mr. Owen Harris    male   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
      "2                             Heikkinen, Miss. Laina  female   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
      "4                           Allen, Mr. William Henry    male   \n",
      "\n",
      "             Ticket Cabin Embarked  \n",
      "0         A/5 21171   NaN        S  \n",
      "1          PC 17599   C85        C  \n",
      "2  STON/O2. 3101282   NaN        S  \n",
      "3            113803  C123        S  \n",
      "4            373450   NaN        S  \n",
      "Numerical Columns:\n",
      "    PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare\n",
      "0            1         0       3  22.0      1      0   7.2500\n",
      "1            2         1       1  38.0      1      0  71.2833\n",
      "2            3         1       3  26.0      0      0   7.9250\n",
      "3            4         1       1  35.0      1      0  53.1000\n",
      "4            5         0       3  35.0      0      0   8.0500\n",
      "All the column names:  Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Categorical Columns:\n",
      "  ['Sex', 'Embarked']\n",
      "Fare of ticket when no cabin was assigned count    687.000000\n",
      "mean      19.157325\n",
      "std       28.663343\n",
      "min        0.000000\n",
      "25%        7.877100\n",
      "50%       10.500000\n",
      "75%       23.000000\n",
      "max      512.329200\n",
      "Name: Fare, dtype: float64\n",
      "Fare of ticket for people who had cabin assigned to them count    204.000000\n",
      "mean      76.141504\n",
      "std       74.391749\n",
      "min        0.000000\n",
      "25%       29.453125\n",
      "50%       55.220850\n",
      "75%       89.328150\n",
      "max      512.329200\n",
      "Name: Fare, dtype: float64\n",
      "Survival of people with no cabins AxesSubplot(0.125,0.125;0.352273x0.755)\n",
      "Survival of people with cabins AxesSubplot(0.547727,0.125;0.352273x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket\n",
      "1    92\n",
      "2    85\n",
      "3    72\n",
      "P    42\n",
      "S    21\n",
      "C    16\n",
      "F     4\n",
      "W     2\n",
      "A     2\n",
      "4     2\n",
      "L     1\n",
      "9     1\n",
      "7     1\n",
      "6     1\n",
      "8     0\n",
      "5     0\n",
      "Name: Survived, dtype: int64\n",
      "Ticket\n",
      "CA. 2343    7\n",
      "1601        7\n",
      "347082      7\n",
      "347088      6\n",
      "CA 2144     6\n",
      "           ..\n",
      "PC 17601    1\n",
      "349239      1\n",
      "349240      1\n",
      "349241      1\n",
      "347464      1\n",
      "Length: 681, dtype: int64\n",
      "Ticket\n",
      "1    111\n",
      "P     44\n",
      "3     22\n",
      "2     15\n",
      "S      4\n",
      "W      3\n",
      "C      2\n",
      "F      1\n",
      "6      1\n",
      "5      1\n",
      "L      0\n",
      "A      0\n",
      "9      0\n",
      "8      0\n",
      "7      0\n",
      "4      0\n",
      "dtype: int64\n",
      "['A' 'P' 'S' '1' '3' '2' 'C' '7' 'W' '4' 'F' 'L' '9' '6' '5' '8']\n"
     ]
    }
   ],
   "source": [
    "y = tit.Survived\n",
    "\n",
    "# Drop rows with empty target value\n",
    "tit = tit.dropna(subset=['Survived'])\n",
    "\n",
    "print('NA values per column:\\n',pd.isnull(tit).sum(),tit.shape) # How many empty values for each column\n",
    "\n",
    "#tit = tit.dropna() # Very basic means of handling missing values. Not encouraged\n",
    "#print(pd.isnull(tit).sum(),tit.shape)\n",
    "\n",
    "# As you can see dropna dropped rows with very useful info. So go for other approaches\n",
    "\n",
    "numerical_cols = tit.select_dtypes(exclude=['object']).columns\n",
    "categorical_cols = [col for col in tit.columns if tit[col].dtype == 'object' and tit[col].nunique()<10]\n",
    "object_cols = tit.select_dtypes(include=['object']).columns\n",
    "print(\"Object columns:\\n\",tit[object_cols].head())\n",
    "print(\"Numerical Columns:\\n\",tit[numerical_cols].head())\n",
    "print(\"All the column names: \",tit.columns)\n",
    "\n",
    "print(\"Categorical Columns:\\n \", categorical_cols)\n",
    "\n",
    "print(\"Fare of ticket when no cabin was assigned\",tit.loc[tit.Cabin.isna(),'Fare'].describe())\n",
    "print(\"Fare of ticket for people who had cabin assigned to them\",tit.loc[tit.Cabin.notna(),'Fare'].describe())\n",
    "\n",
    "# So this is an indication of division of poor/rich. Let's confim if there is a direct correlation to their survivial\n",
    "plt.subplot(1,2,1)\n",
    "print(\"Survival of people with no cabins\",tit.loc[tit.Cabin.isna(),'Survived'].hist())\n",
    "plt.subplot(1,2,2)\n",
    "print(\"Survival of people with cabins\",tit.loc[tit.Cabin.notna(),'Survived'].hist())\n",
    "plt.show()\n",
    "#So high percetage of people with cabins survived as compared to people with no cabins. \n",
    "#So while imputing NaN or NA values of Cabin add extra column of cabin missing or not.\n",
    "\n",
    "#Let's find out the correlation between cabin number and survival\n",
    "\n",
    "tit.groupby('Cabin').Survived.sum().sort_values(ascending=False)\n",
    "\n",
    "# No correlation as such so probably we can replace cabin column with cabin_was_missing column.\n",
    "\n",
    "tit.groupby(\"Pclass\").apply(lambda p : p.Survived.sum())\n",
    "\n",
    "#Many people belonging to Passenger class 1 survived.\n",
    "\n",
    "tit.groupby(\"Pclass\").apply(lambda p: p.Cabin.notna().sum()) # Number of passenger per class who had their cabin assigned to them\n",
    "\n",
    "#Majority of class 1 had cabin assigned to them\n",
    "\n",
    "tit.groupby(\"Embarked\").Survived.sum()\n",
    "\n",
    "#Many who came from S:Southampton survived.\n",
    "#Were they rich or had cabins by any chance?\n",
    "\n",
    "tit.groupby(\"Embarked\").apply(lambda p: p.Cabin.notna().sum())\n",
    "\n",
    "#Majority of SOuthampton passenegers had cabins.\n",
    "\n",
    "tit.groupby(\"Sex\").Survived.sum()\n",
    "\n",
    "#More females survived than men. Meaning women were evacuated first.\n",
    "\n",
    "\n",
    "tit.groupby(\"Age\").Survived.sum().sort_values(ascending=False)\n",
    "\n",
    "# Age at first look doesnt seem to decide the Survival as such\n",
    "\n",
    "tit.groupby(\"Ticket\").Survived.sum().sort_values(ascending=False)\n",
    "\n",
    "# For ticket number, individual outliers that cannot be correlated or generalised.\n",
    "\n",
    "tit.groupby(\"Fare\").Survived.sum().sort_values(ascending=True)\n",
    "\n",
    "#Not a good indicator of survival\n",
    "\n",
    "#How first two characters of Ticket decide Survival\n",
    "print(tit.groupby(tit.Ticket.map(lambda p: p[0])).Survived.sum().sort_values(ascending=False))\n",
    "#Number of people per ticket\n",
    "print(tit.groupby(\"Ticket\").size().sort_values(ascending=False))\n",
    "\n",
    "#For each ticket type (first 2 characters) how many Cabins were assigned\n",
    "print(tit.groupby(tit.Ticket.map(lambda p: p[0])).apply(lambda p: p.Cabin.notna().sum()).sort_values(ascending=False))\n",
    "\n",
    "# You can try to use tit.Ticket.map(lambda p: p[0]) as a feature.\n",
    "print(tit.Ticket.map(lambda p: p[0]).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Feature Generation and Selection ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin_Was_missing</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  Cabin_Was_missing Embarked  Family\n",
       "0         3    male  22.0               True        S       1\n",
       "1         1  female  38.0              False        C       1\n",
       "2         3  female  26.0               True        S       0\n",
       "3         1  female  35.0              False        S       1\n",
       "4         3    male  35.0               True        S       0\n",
       "..      ...     ...   ...                ...      ...     ...\n",
       "886       2    male  27.0               True        S       0\n",
       "887       1  female  19.0              False        S       0\n",
       "888       3  female   NaN               True        S       3\n",
       "889       1    male  26.0              False        C       0\n",
       "890       3    male  32.0               True        Q       0\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tit[\"Cabin_Was_missing\"] = tit.Cabin.isna()\n",
    "tit_test[\"Cabin_Was_missing\"] = tit_test.Cabin.isna()\n",
    "\n",
    "tit[\"Ticket_First_Char\"] = tit.Ticket.map(lambda p: p[0])\n",
    "tit_test[\"Ticket_First_Char\"] = tit_test.Ticket.map(lambda p: p[0])\n",
    "\n",
    "tit[\"Family\"] = tit.apply(lambda p: (int(pd.notnull(p.SibSp)) * p.SibSp) + (int(pd.notnull(p.Parch)) * p.Parch),axis='columns') #Total number of family memebers per passenger\n",
    "tit_test[\"Family\"] = tit_test.apply(lambda p: (int(pd.notnull(p.SibSp)) * p.SibSp) + (int(pd.notnull(p.Parch)) * p.Parch),axis='columns')\n",
    "\n",
    "#Extra checks in case a value is null like SibSp and other is not. Then total family should not be NaN or NA but its has to be still Parch.\n",
    "\n",
    "#Include the above column as part of your features instead of Cabin column\n",
    "\n",
    "features = [\"Pclass\",\"Sex\",\"Age\",\"Cabin_Was_missing\",\"Embarked\",\"Family\"] \n",
    "# Sex and Embarked are categorical with low cardinality\n",
    "\n",
    "X = tit[features]\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X,y)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Pclass_pre = SimpleImputer(strategy='most_frequent')\n",
    "Age_pre = SimpleImputer(strategy='mean')\n",
    "tit.Sex = tit.Sex.fillna(method=\"bfill\").fillna(\"Non-binary\") # If Sex is undefined/NA assume it to be Non-binary\n",
    "Sex_pre = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "Embarked_pre = Pipeline(steps=[(\"embarked_impute\",SimpleImputer(strategy = 'most_frequent')),\n",
    "                              (\"embarked_encode\",OneHotEncoder(handle_unknown='ignore',sparse=False))])\n",
    "# Missing values in Family depends upon Parch and SibSp values. But it is handled at creation of \"Family\" feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine preprocessing steps ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoid Train Test Contamination by first splitting the dataset into Training and Validation set\n",
    "preprocessing = ColumnTransformer(transformers=[(\"Pclass\",Pclass_pre,[\"Pclass\"]),\n",
    "                                              (\"Age\",Age_pre,[\"Age\"]),\n",
    "                                                (\"Sex\",Sex_pre,[\"Sex\"]),\n",
    "                                                (\"Embarked\",Embarked_pre,[\"Embarked\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE at 5 max_leaf_nodes:  0.18834080717488788\n",
      "MAE at 9 max_leaf_nodes:  0.15246636771300448\n",
      "MAE at 10 max_leaf_nodes:  0.15246636771300448\n",
      "MAE at 12 max_leaf_nodes:  0.15246636771300448\n",
      "MAE at 14 max_leaf_nodes:  0.15695067264573992\n",
      "MAE at 15 max_leaf_nodes:  0.15246636771300448\n",
      "MAE at 17 max_leaf_nodes:  0.15695067264573992\n",
      "MAE at 18 max_leaf_nodes:  0.15695067264573992\n",
      "MAE at 19 max_leaf_nodes:  0.15695067264573992\n",
      "MAE at 20 max_leaf_nodes:  0.15246636771300448\n",
      "MAE at 30 max_leaf_nodes:  0.17040358744394618\n",
      "MAE at 50 max_leaf_nodes:  0.16591928251121077\n",
      "MAE at 75 max_leaf_nodes:  0.16143497757847533\n",
      "MAE at 100 max_leaf_nodes:  0.18385650224215247\n",
      "MAE at 125 max_leaf_nodes:  0.18385650224215247\n",
      "MAE at 150 max_leaf_nodes:  0.18385650224215247\n",
      "MAE at 175 max_leaf_nodes:  0.18385650224215247\n",
      "MAE at 200 max_leaf_nodes:  0.18385650224215247\n",
      "MAE at 250 max_leaf_nodes:  0.18385650224215247\n",
      "MAE at 500 max_leaf_nodes:  0.18385650224215247\n"
     ]
    }
   ],
   "source": [
    "def error(max_leaf_nodes):\n",
    "    model = RandomForestClassifier(max_leaf_nodes=max_leaf_nodes,random_state=0)\n",
    "    my_pipeline = Pipeline(steps=[(\"preprocessing\",preprocessing),\n",
    "                                 (\"model\",model)])\n",
    "    my_pipeline.fit(X_train,y_train)\n",
    "    return mean_absolute_error(y_valid,my_pipeline.predict(X_valid))\n",
    "\n",
    "for m in [5,9,10,12,14,15,17,18,19,20,30,50,75,100,125,150,175,200,250,500]:\n",
    "    print(\"MAE at {} max_leaf_nodes: \".format(m),error(m))\n",
    "# Therefore choose max_leaf_nodes = 18 or 19 or 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0,max_leaf_nodes=20)\n",
    "random_model = RandomForestClassifier(random_state=42,n_estimators=800,min_samples_split=2,min_samples_leaf=4,max_features='sqrt',max_depth=90,bootstrap=True)\n",
    "#{'model__n_estimators': 800, 'model__min_samples_split': 2, 'model__min_samples_leaf': 4, 'model__max_features': 'sqrt', 'model__max_depth': 90, 'model__bootstrap': True}\n",
    "#{'model__n_estimators': 800, 'model__min_samples_split': 2, 'model__min_samples_leaf': 4, 'model__max_features': 'sqrt', 'model__max_depth': 40, 'model__bootstrap': False}\n",
    "#{'model__n_estimators': 2000, 'model__min_samples_split': 5, 'model__min_samples_leaf': 4, 'model__max_features': 'auto', 'model__max_depth': None, 'model__bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE when pipeline is deployed:  0.15246636771300448\n"
     ]
    }
   ],
   "source": [
    "my_pipeline = Pipeline(steps=[(\"preprocessing\",preprocessing),\n",
    "                             (\"model\",model)])\n",
    "# To include early_stopping_rounds and manipulate other parameters(not possible at model definition stage)called Hypertuning Parameters, onto model while fitting data, use GridSearchCV part of model_selection package. https://www.kaggle.com/aashita/advanced-pipelines-tutorial\n",
    "random_pipeline = Pipeline(steps=[('Preprocessing',preprocessing),('model',random_model)])\n",
    "my_pipeline.fit(X_train,y_train)\n",
    "random_pipeline.fit(X_train,y_train)\n",
    "print(\"MAE when pipeline is deployed: \",mean_absolute_error(y_valid,my_pipeline.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation (since small dataset) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross Validation Error across 5 folds for base model:  0.1919151340154416\n",
      "Average CV Error acroos 5 folds for random model: 0.20423702215805664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_validation_error = -1 * cross_val_score(my_pipeline,X,y,cv=5,scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Average Cross Validation Error across 5 folds for base model: \",cross_validation_error.mean())\n",
    "\n",
    "cross_validation_error_random = -1 * cross_val_score(random_pipeline,X,y,cv=5,scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "print(\"Average CV Error acroos 5 folds for random model:\",cross_validation_error_random.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__n_estimators': 600, 'model__min_samples_split': 5, 'model__min_samples_leaf': 2, 'model__max_features': 'auto', 'model__max_depth': 80, 'model__bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Deafult values of attributes of Random Forest\n",
    "# {'bootstrap': True,\n",
    "#  'criterion': 'mse',\n",
    "#  'max_depth': None,\n",
    "#  'max_features': 'auto',\n",
    "#  'max_leaf_nodes': None,\n",
    "#  'min_impurity_decrease': 0.0,\n",
    "#  'min_impurity_split': None,\n",
    "#  'min_samples_leaf': 1,\n",
    "#  'min_samples_split': 2,\n",
    "#  'min_weight_fraction_leaf': 0.0,\n",
    "#  'n_estimators': 10,\n",
    "#  'n_jobs': 1,\n",
    "#  'oob_score': False,\n",
    "#  'random_state': 42,\n",
    "#  'verbose': 0,\n",
    "#  'warm_start': False}\n",
    "param_grid = { 'model__bootstrap': [True, False],\n",
    " 'model__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'model__max_features': ['auto', 'sqrt'],\n",
    " 'model__min_samples_leaf': [1, 2, 4],\n",
    " 'model__min_samples_split': [2, 5, 10],\n",
    " 'model__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "              \n",
    "    \n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=my_pipeline, param_distributions = param_grid,cv = 5, n_iter=100, n_jobs = -1, verbose = 2)\n",
    "#n_jobs = -1 means use all the available cores and n_iter=100 means search acroos 100 different combinations\n",
    "\n",
    "# Fit the grid search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "print(random_search.best_params_)\n",
    "# {'model__max_depth': 80, 'model__max_features': 2, 'model__min_samples_leaf': 4, 'model__min_samples_split': 12, 'model__n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Test Set ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_preds = pd.DataFrame(my_pipeline.predict(tit_test[features]))\n",
    "\n",
    "my_preds.columns = [\"Survived\"]\n",
    "\n",
    "my_preds = my_preds.set_index(tit_test.PassengerId)\n",
    "\n",
    "my_preds = my_preds.rename_axis(\"PassengerId\",axis='rows')\n",
    "\n",
    "\n",
    "my_preds.to_csv(\"C://Users//91836//Documents//DataSets//Titanic//preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further avenues to explore ###\n",
    "Explore HyperParamter Tuning for XGBClassifier and Model Selection for RandomForestClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
